"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[9430],{4137:function(e,t,n){n.d(t,{Zo:function(){return u},kt:function(){return h}});var a=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var s=a.createContext({}),p=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},u=function(e){var t=p(e.components);return a.createElement(s.Provider,{value:t},e.children)},d="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,i=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),d=p(n),m=o,h=d["".concat(s,".").concat(m)]||d[m]||c[m]||i;return n?a.createElement(h,r(r({ref:t},u),{},{components:n})):a.createElement(h,r({ref:t},u))}));function h(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var i=n.length,r=new Array(i);r[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[d]="string"==typeof e?e:o,r[1]=l;for(var p=2;p<i;p++)r[p]=n[p];return a.createElement.apply(null,r)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},6624:function(e,t,n){n.r(t),n.d(t,{contentTitle:function(){return s},default:function(){return m},frontMatter:function(){return l},metadata:function(){return p},toc:function(){return u}});var a=n(7462),o=n(3366),i=(n(7294),n(4137)),r=["components"],l={title:"Apache Pinot\u2122 0.11 - Deduplication on Real-Time Tables",author:"Mark Needham",author_title:"Mark Needham",author_url:"https://www.linkedin.com/in/lakshmanan-velusamy-a778a517/",author_image_url:"https://www.datocms-assets.com/75153/1661544338-mark-needham.png",description:"Learn about the deduplication for the real-time tables feature in Apache Pinot",keywords:["Apache Pinot","Apache Pinot 0.11.0","deduplication"],tags:["Pinot","Data","Analytics","User-Facing Analytics","deduplication"]},s=void 0,p={permalink:"/blog/2023/01/29/Apache-Pinot-Deduplication-on-Real-Time-Tables",editUrl:"https://github.com/apache/pinot-site/edit/dev/website/blog/2023-01-29-Apache-Pinot-Deduplication-on-Real-Time-Tables.md",source:"@site/blog/2023-01-29-Apache-Pinot-Deduplication-on-Real-Time-Tables.md",title:"Apache Pinot\u2122 0.11 - Deduplication on Real-Time Tables",description:"Learn about the deduplication for the real-time tables feature in Apache Pinot",date:"2023-01-29T00:00:00.000Z",formattedDate:"January 29, 2023",tags:[{label:"Pinot",permalink:"/blog/tags/pinot"},{label:"Data",permalink:"/blog/tags/data"},{label:"Analytics",permalink:"/blog/tags/analytics"},{label:"User-Facing Analytics",permalink:"/blog/tags/user-facing-analytics"},{label:"deduplication",permalink:"/blog/tags/deduplication"}],readingTime:7.335,truncated:!1,prevItem:{title:"Apache Pinot\u2122 0.12 - Configurable Time Boundary",permalink:"/blog/2023/02/21/Apache-Pinot-0-12-Configurable-Time-Boundary"},nextItem:{title:"Apache Pinot\u2122 0.11 - Pausing Real-Time Ingestion",permalink:"/blog/2022/11/28/Apache-Pinot-Pausing-Real-Time-Ingestion"}},u=[{value:"Why do we need deduplication on real-time tables?",id:"why-do-we-need-deduplication-on-real-time-tables",children:[]},{value:"How does dedup differ from upserts?",id:"how-does-dedup-differ-from-upserts",children:[]},{value:"Setting up Apache Kafka and Apache Pinot",id:"setting-up-apache-kafka-and-apache-pinot",children:[]},{value:"Data Generation",id:"data-generation",children:[]},{value:"Pinot Schema/Table Config",id:"pinot-schematable-config",children:[]},{value:"How does it work?\xa0",id:"how-does-it-work",children:[]},{value:"Summary",id:"summary",children:[]}],d={toc:u},c="wrapper";function m(e){var t=e.components,n=(0,o.Z)(e,r);return(0,i.kt)(c,(0,a.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,"Last fall, the Apache Pinot community released version ",(0,i.kt)("a",{parentName:"p",href:"https://medium.com/apache-pinot-developer-blog/apache-pinot-0-11-released-d564684df5d4"},"0.11.0"),", which has lots of goodies for you to play with."),(0,i.kt)("p",null,"In this post, we\u2019re going to learn about the ",(0,i.kt)("a",{parentName:"p",href:"https://docs.pinot.apache.org/basics/data-import/dedup"},"deduplication for the real-time tables feature"),".\xa0"),(0,i.kt)("h2",{id:"why-do-we-need-deduplication-on-real-time-tables"},"Why do we need deduplication on real-time tables?"),(0,i.kt)("p",null,"This feature was built to deal with duplicate data in the streaming platform.\xa0"),(0,i.kt)("p",null,"Users have previously used the upsert feature to de-duplicate data, but this has the following limitations:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"It forces us to keep redundant records that we don\u2019t want to keep, which increases overall storage costs."),(0,i.kt)("li",{parentName:"ul"},"We can\u2019t yet use the StarTree index with upserts, so the speed benefits we get from using that indexing technique are lost.")),(0,i.kt)("h2",{id:"how-does-dedup-differ-from-upserts"},"How does dedup differ from upserts?"),(0,i.kt)("p",null,"Both upserts and dedup keep track of multiple documents that have the same primary key. They differ as follows:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Upserts are used when we want to get the latest copy of a document for a given primary key. It\u2019s likely that some or all of the other fields will be different. Pinot stores all documents it receives, but when querying it will only return the latest document for each primary key."),(0,i.kt)("li",{parentName:"ul"},"Dedup is used when we know that multiple documents with the same primary key are identical. Only the first event received for a given primary key is stored in Pinot\u2014any future events with the same primary key are thrown away.")),(0,i.kt)("p",null,"Let\u2019s see how to use this functionality with help from a worked example."),(0,i.kt)("h2",{id:"setting-up-apache-kafka-and-apache-pinot"},"Setting up Apache Kafka and Apache Pinot"),(0,i.kt)("p",null,"We\u2019re going to spin up Kafka and Pinot using the following Docker Compose config:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},'version: "3"\nservices:\n  zookeeper:\n    image: zookeeper:3.8.0\n    hostname: zookeeper\n    container_name: zookeeper-dedup-blog\n    ports:\n      - "2181:2181"\n    environment:\n      ZOOKEEPER_CLIENT_PORT: 2181\n      ZOOKEEPER_TICK_TIME: 2000\n    networks: \n      - dedup_blog\n  kafka:\n    image: wurstmeister/kafka:latest\n    restart: unless-stopped\n    container_name: "kafka-dedup-blog"\n    ports:\n      - "9092:9092"\n    expose:\n      - "9093"\n    depends_on:\n     - zookeeper\n    environment:\n      KAFKA_ZOOKEEPER_CONNECT: zookeeper-dedup-blog:2181/kafka\n      KAFKA_BROKER_ID: 0\n      KAFKA_ADVERTISED_HOST_NAME: kafka-dedup-blog\n      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-dedup-blog:9093,OUTSIDE://localhost:9092\n      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9093,OUTSIDE://0.0.0.0:9092\n      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,OUTSIDE:PLAINTEXT\n    networks: \n      - dedup_blog\n  pinot-controller:\n    image: apachepinot/pinot:0.11.0-arm64\n    command: "QuickStart -type EMPTY"\n    container_name: "pinot-controller-dedup-blog"\n    volumes:\n      - ./config:/config\n    restart: unless-stopped\n    ports:\n      - "9000:9000"\n    networks: \n      - dedup_blog\nnetworks:\n  dedup_blog:\n    name: dedup_blog\n\n')),(0,i.kt)("p",null,"We can spin up our infrastructure using the following command:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"docker-compose up\n")),(0,i.kt)("h2",{id:"data-generation"},"Data Generation"),(0,i.kt)("p",null,"Let\u2019s imagine that we want to ingest events generated by the following Python script:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'import datetime\nimport uuid\nimport random\nimport json\n\nwhile True:\n    ts = datetime.datetime.now().strftime("%Y-%m-%dT%H:%M:%S.%fZ")\n    id = str(uuid.uuid4())\n    count = random.randint(0, 1000)\n    print(\n        json.dumps({"tsString": ts, "uuid": id[:3], "count": count})\n    )\n')),(0,i.kt)("p",null,"We can view the data generated by this script by pasting the above code into a file called datagen.py and then running the following command:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"python datagen.py 2>/dev/null | head -n3 | jq\n")),(0,i.kt)("p",null,"We\u2019ll see the following output:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "tsString": "2023-01-03T10:59:17.355081Z",\n  "uuid": "f94",\n  "count": 541\n}\n{\n  "tsString": "2023-01-03T10:59:17.355125Z",\n  "uuid": "057",\n  "count": 96\n}\n{\n  "tsString": "2023-01-03T10:59:17.355141Z",\n  "uuid": "d7b",\n  "count": 288\n}\n')),(0,i.kt)("p",null,"If we generate only 25,000 events, we\u2019ll get some duplicates, which we can see by running the following command:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"python datagen.py 2>/dev/null  | \njq -r '.uuid' | head -n25000 | uniq -cd\n")),(0,i.kt)("p",null,"The results of running that command are shown below:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-text"},"2 3a2\n2 a04\n2 433\n2 291\n2 d73\n")),(0,i.kt)("p",null,"We\u2019re going to pipe this data into a Kafka stream called events, like this:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"python datagen.py 2>/dev/null | \njq -cr --arg sep \ud83d\ude0a '[.uuid, tostring] | join($sep)' | \nkcat -P -b localhost:9092 -t events -K\ud83d\ude0a\n")),(0,i.kt)("p",null,"The construction of the key/value structure comes from Robin Moffatt\u2019s ",(0,i.kt)("a",{parentName:"p",href:"https://rmoff.net/2020/09/30/setting-key-value-when-piping-from-jq-to-kafkacat/"},"excellent blog post"),". Since that blog post was written, kcat has started supporting multi byte separators, which is why we can use a smiley face to separate our key and value."),(0,i.kt)("h2",{id:"pinot-schematable-config"},"Pinot Schema/Table Config"),(0,i.kt)("p",null,"Next, we\u2019re going to create a Pinot table and schema with the same name. Let\u2019s first define a schema:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "schemaName": "events",\n  "dimensionFieldSpecs": [{"name": "uuid", "dataType": "STRING"}],\n  "metricFieldSpecs": [{"name": "count", "dataType": "INT"}],\n  "dateTimeFieldSpecs": [\n    {\n      "name": "ts",\n      "dataType": "TIMESTAMP",\n      "format": "1:MILLISECONDS:EPOCH",\n      "granularity": "1:MILLISECONDS"\n    }\n  ]\n}\n')),(0,i.kt)("p",null,"Note that the timestamp field is called ts and not tsString, as it is in the Kafka stream. We\u2019re going to transform the DateTime string value held in that field into a proper timestamp using a transformation function.\xa0"),(0,i.kt)("p",null,"Our table config is described below:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "tableName": "events",\n  "tableType": "REALTIME",\n  "segmentsConfig": {\n    "timeColumnName": "ts",\n    "schemaName": "events",\n    "replication": "1",\n    "replicasPerPartition": "1"\n  },\n  "tableIndexConfig": {\n    "loadMode": "MMAP",\n    "streamConfigs": {\n      "streamType": "kafka",\n      "stream.kafka.topic.name": "events",\n      "stream.kafka.broker.list": "kafka-dedup-blog:9093",\n      "stream.kafka.consumer.type": "lowlevel",\n      "stream.kafka.consumer.prop.auto.offset.reset": "smallest",\n      "stream.kafka.consumer.factory.class.name": "org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory",\n      "stream.kafka.decoder.class.name": "org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder"\n    }\n  },\n  "ingestionConfig": {\n    "transformConfigs": [\n      {\n        "columnName": "ts",\n        "transformFunction": "FromDateTime(tsString, \'YYYY-MM-dd\'\'T\'\'HH:mm:ss.SSSSSS\'\'Z\'\'\')"\n      }\n    ]\n  },\n  "tenants": {},\n  "metadata": {}\n}\n')),(0,i.kt)("p",null,"Let\u2019s create the table using the following command:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'docker run \\\n   --network dedup_blog \\\n   -v $PWD/pinot/config:/config \\\n   apachepinot/pinot:0.11.0-arm64 AddTable \\\n     -schemaFile /config/schema.json \\\n     -tableConfigFile /config/table.json \\\n     -controllerHost "pinot-controller-dedup-blog" \\\n    -exec \n')),(0,i.kt)("p",null,"Now we can navigate to ",(0,i.kt)("a",{parentName:"p",href:"http://localhost:9000/"},"http://localhost:9000")," and run a query that will return a count of the number of each uuid:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"select uuid, count(*)\nfrom events \ngroup by uuid\norder by count(*)\nlimit 10\n")),(0,i.kt)("p",null,"The results of this query are shown below:"),(0,i.kt)("p",null,(0,i.kt)("img",{parentName:"p",src:"https://www.datocms-assets.com/75153/1673273173-image4.png",alt:"Sample Apache Pinot real-time query response stats including duplicates",title:"Sample Apache Pinot real-time query response stats including duplicates"})),(0,i.kt)("p",null,"We can see loads of duplicates!\xa0"),(0,i.kt)("p",null,"Now let\u2019s add a table and schema that uses the de-duplicate feature, starting with the schema:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "schemaName": "events_dedup",\n  "primaryKeyColumns": ["uuid"],\n  "dimensionFieldSpecs": [{"name": "uuid", "dataType": "STRING"}],\n  "metricFieldSpecs": [{"name": "count", "dataType": "INT"}],\n  "dateTimeFieldSpecs": [\n    {\n      "name": "ts",\n      "dataType": "TIMESTAMP",\n      "format": "1:MILLISECONDS:EPOCH",\n      "granularity": "1:MILLISECONDS"\n    }\n  ]\n}\n')),(0,i.kt)("p",null,"The main difference between this schema and the events schema is that we need to specify a primary key. This key can be any number of fields, but in this case, we\u2019re only using the uuid field."),(0,i.kt)("p",null,"Next, the table config:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "tableName": "events_dedup",\n  "tableType": "REALTIME",\n  "segmentsConfig": {\n    "timeColumnName": "ts",\n    "schemaName": "events_dedup",\n    "replication": "1",\n    "replicasPerPartition": "1"\n  },\n  "tableIndexConfig": {\n    "loadMode": "MMAP",\n    "streamConfigs": {\n      "streamType": "kafka",\n      "stream.kafka.topic.name": "events",\n      "stream.kafka.broker.list": "kafka-dedup-blog:9093",\n      "stream.kafka.consumer.type": "lowlevel",\n      "stream.kafka.consumer.prop.auto.offset.reset": "smallest",\n      "stream.kafka.consumer.factory.class.name": "org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory",\n      "stream.kafka.decoder.class.name": "org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder"\n    }\n  },\n  "routing": {"instanceSelectorType": "strictReplicaGroup"},\n  "dedupConfig": {"dedupEnabled": true, "hashFunction": "NONE"},\n  "ingestionConfig": {\n    "transformConfigs": [\n      {\n        "columnName": "ts",\n        "transformFunction": "FromDateTime(tsString, \'YYYY-MM-dd\'\'T\'\'HH:mm:ss.SSSSSS\'\'Z\'\'\')"\n      }\n    ]\n  },\n  "tenants": {},\n  "metadata": {}\n}\n')),(0,i.kt)("p",null,"The changes to notice here are:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},'"dedupConfig": {"dedupEnabled": true, "hashFunction": "NONE"} - This enables the feature and indicates that we won\u2019t use a hash function on our primary key.'),(0,i.kt)("li",{parentName:"ul"},'"routing": {"instanceSelectorType": "strictReplicaGroup"} - This makes sure that all segments of the same partition are served from the same server to ensure data consistency across the segments.\xa0')),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'docker run \\\n   --network dedup_blog \\\n   -v $PWD/pinot/config:/config \\\n   apachepinot/pinot:0.11.0-arm64 AddTable \\\n     -schemaFile /config/schema-dedup.json \\\n     -tableConfigFile /config/table-dedup.json \\\n     -controllerHost "pinot-controller-dedup-blog" \\\n    -exec\n\nselect uuid, count(*)\nfrom events_dedup\ngroup by uuid\norder by count(*)\nlimit 10\n')),(0,i.kt)("p",null,(0,i.kt)("img",{parentName:"p",src:"https://www.datocms-assets.com/75153/1673273248-image3.png",alt:"Sample Apache Pinot real-time query response stats deduplicated",title:"Sample Apache Pinot real-time query response stats deduplicated"})),(0,i.kt)("p",null,"We have every combination of hex values (16^3=4096) and no duplicates! Pinot\u2019s de-duplication feature has done its job."),(0,i.kt)("h2",{id:"how-does-it-work"},"How does it work?\xa0"),(0,i.kt)("p",null,"When we\u2019re not using the deduplication feature, events are ingested from our streaming platform into Pinot, as shown in the diagram below:"),(0,i.kt)("p",null,(0,i.kt)("img",{parentName:"p",src:"https://www.datocms-assets.com/75153/1673273272-pinot_0-11-de-duplication-diagram_1-v2.png",alt:"Events ingested from a streaming platform into Apache Pinot without using the deduplication feature",title:"Events ingested from a streaming platform into Apache Pinot without using the deduplication feature"})),(0,i.kt)("p",null,"When de-dup is enabled, we have to check whether records can be ingested, as shown in the diagram below:"),(0,i.kt)("p",null,(0,i.kt)("img",{parentName:"p",src:"https://www.datocms-assets.com/75153/1673273289-pinot_0-11-de-duplication-diagram_2-v3.png",alt:"Events ingested from a streaming platform into Apache Pinot using the deduplication feature",title:"Events ingested from a streaming platform into Apache Pinot using the deduplication feature"})),(0,i.kt)("p",null,"De-dup works out whether a primary key has already been ingested by using an in memory map of (primary key -> corresponding segment reference)."),(0,i.kt)("p",null,"We need to take that into account when using this feature, otherwise, we\u2019ll end up using all the available memory on the Pinot Server. Below are some tips for using this feature:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Try to use a simple primary key type and avoid composite keys. If you don\u2019t have a simple primary key, consider using one of the available hash functions to reduce the space taken up."),(0,i.kt)("li",{parentName:"ul"},"Create more partitions in the streaming platform than you might otherwise create. The number of partitions determines the partition numbers of the Pinot table. The more partitions you have in the streaming platform, the more Pinot servers you can distribute the Pinot table to, and the more horizontally scalable the table will be.")),(0,i.kt)("h2",{id:"summary"},"Summary"),(0,i.kt)("p",null,"This feature makes it easier to ensure that we don\u2019t end up with duplicate data in our Apache Pinot estate.\xa0"),(0,i.kt)("p",null,"So give it a try and let us know how you get on. If you have any questions about this feature, feel free to join us on ",(0,i.kt)("a",{parentName:"p",href:"https://stree.ai/slack"},"Slack"),", where we\u2019ll be happy to help you out."),(0,i.kt)("p",null,"And if you\u2019re interested in how this feature was implemented, you can look at the ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/apache/pinot/pull/8708"},"pull request on GitHub"),"."))}m.isMDXComponent=!0}}]);