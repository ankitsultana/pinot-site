"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[8453],{4137:function(e,t,n){n.d(t,{Zo:function(){return p},kt:function(){return g}});var a=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function s(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?s(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):s(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},s=Object.keys(e);for(a=0;a<s.length;a++)n=s[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(a=0;a<s.length;a++)n=s[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var r=a.createContext({}),u=function(e){var t=a.useContext(r),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},p=function(e){var t=u(e.components);return a.createElement(r.Provider,{value:t},e.children)},m="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},h=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,s=e.originalType,r=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),m=u(n),h=o,g=m["".concat(r,".").concat(h)]||m[h]||c[h]||s;return n?a.createElement(g,i(i({ref:t},p),{},{components:n})):a.createElement(g,i({ref:t},p))}));function g(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var s=n.length,i=new Array(s);i[0]=h;var l={};for(var r in t)hasOwnProperty.call(t,r)&&(l[r]=t[r]);l.originalType=e,l[m]="string"==typeof e?e:o,i[1]=l;for(var u=2;u<s;u++)i[u]=n[u];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}h.displayName="MDXCreateElement"},6204:function(e,t,n){n.r(t),n.d(t,{contentTitle:function(){return r},default:function(){return h},frontMatter:function(){return l},metadata:function(){return u},toc:function(){return p}});var a=n(7462),o=n(3366),s=(n(7294),n(4137)),i=["components"],l={title:"Apache Pinot\u2122 0.11 - Pausing Real-Time Ingestion",author:"Mark Needham",author_title:"Mark Needham",author_url:"https://www.linkedin.com/in/lakshmanan-velusamy-a778a517/",author_image_url:"https://www.datocms-assets.com/75153/1661544338-mark-needham.png",description:"Learn about a feature that lets you pause and resume real-time data ingestion in Apache Pinot",keywords:["Apache Pinot","Apache Pinot 0.11.0","pause resume","real-time ingestion"],tags:["Pinot","Data","Analytics","User-Facing Analytics","pause","resume","real-time ingestion"]},r=void 0,u={permalink:"/blog/2022/11/28/Apache-Pinot-Pausing-Real-Time-Ingestion",editUrl:"https://github.com/apache/pinot-site/edit/dev/website/blog/2022-11-28-Apache-Pinot-Pausing-Real-Time-Ingestion.md",source:"@site/blog/2022-11-28-Apache-Pinot-Pausing-Real-Time-Ingestion.md",title:"Apache Pinot\u2122 0.11 - Pausing Real-Time Ingestion",description:"Learn about a feature that lets you pause and resume real-time data ingestion in Apache Pinot",date:"2022-11-28T00:00:00.000Z",formattedDate:"November 28, 2022",tags:[{label:"Pinot",permalink:"/blog/tags/pinot"},{label:"Data",permalink:"/blog/tags/data"},{label:"Analytics",permalink:"/blog/tags/analytics"},{label:"User-Facing Analytics",permalink:"/blog/tags/user-facing-analytics"},{label:"pause",permalink:"/blog/tags/pause"},{label:"resume",permalink:"/blog/tags/resume"},{label:"real-time ingestion",permalink:"/blog/tags/real-time-ingestion"}],readingTime:6.37,truncated:!1,prevItem:{title:"Apache Pinot\u2122 0.11 - Deduplication on Real-Time Tables",permalink:"/blog/2023/01/29/Apache-Pinot-Deduplication-on-Real-Time-Tables"},nextItem:{title:"Apache Pinot\u2122 0.11 - Timestamp Indexes",permalink:"/blog/2022/11/22/Apache-Pinot-Timestamp-Indexes"}},p=[{value:"How does real-time ingestion work?",id:"how-does-real-time-ingestion-work",children:[]},{value:"Why do we need to pause and resume ingestion?",id:"why-do-we-need-to-pause-and-resume-ingestion",children:[]},{value:"Data Generation",id:"data-generation",children:[]},{value:"Pinot Schema/Table Config",id:"pinot-schematable-config",children:[]},{value:"The Pause/Resume Flow",id:"the-pauseresume-flow",children:[]},{value:"Summary",id:"summary",children:[]}],m={toc:p},c="wrapper";function h(e){var t=e.components,n=(0,o.Z)(e,i);return(0,s.kt)(c,(0,a.Z)({},m,n,{components:t,mdxType:"MDXLayout"}),(0,s.kt)("p",null,(0,s.kt)("a",{parentName:"p",href:"https://youtu.be/u9CwDpMZRog"},(0,s.kt)("img",{parentName:"a",src:"https://i3.ytimg.com/vi/u9CwDpMZRog/maxresdefault.jpg",alt:"Watch the video"}))),(0,s.kt)("p",null,"The Apache Pinot community recently released version ",(0,s.kt)("a",{parentName:"p",href:"https://medium.com/apache-pinot-developer-blog/apache-pinot-0-11-released-d564684df5d4"},"0.11.0"),", which has lots of goodies for you to play with."),(0,s.kt)("p",null,"In this post, we will learn about a feature that lets you pause and resume real-time data ingestion. Sajjad Moradi has ",(0,s.kt)("a",{parentName:"p",href:"https://medium.com/apache-pinot-developer-blog/pause-stream-consumption-on-apache-pinot-772a971ef403"},"also written a blog post about this feature"),", so you can treat this post as a complement to that one."),(0,s.kt)("h2",{id:"how-does-real-time-ingestion-work"},"How does real-time ingestion work?"),(0,s.kt)("p",null,"Before we get into this feature, let\u2019s first recap how real-time ingestion works."),(0,s.kt)("p",null,"This only applies to tables that have the REALTIME type. These tables ingest data that comes in from a streaming platform (e.g., Kafka).\xa0"),(0,s.kt)("p",null,"Pinot servers ingest rows into consuming segments that reside in volatile memory.\xa0"),(0,s.kt)("p",null,"Once a segment reaches the ",(0,s.kt)("a",{parentName:"p",href:"https://dev.startree.ai/docs/pinot/recipes/configuring-segment-threshold"},"segment threshold,")," it will be persisted to disk as a completed segment, and a new consuming segment will be created. This new segment takes over the ingestion of new events from the streaming platform."),(0,s.kt)("p",null,"The diagram below shows what things might look like when we\u2019re ingesting data from a Kafka topic that has 3 partitions:"),(0,s.kt)("p",null,(0,s.kt)("img",{parentName:"p",src:"https://www.datocms-assets.com/75153/1669733133-pinot_0-11-realtime_injestion-diagram-v1.png",alt:"Apache pinot 0.11 Real Time Data Ingestion",title:"Apache pinot 0.11 Real Time Data Ingestion"})),(0,s.kt)("p",null,"A table has one consuming segment per partition but would have many completed segments."),(0,s.kt)("h2",{id:"why-do-we-need-to-pause-and-resume-ingestion"},"Why do we need to pause and resume ingestion?"),(0,s.kt)("p",null,"There are many reasons why you might want to pause and resume ingestion of a stream. Some of the common ones are described below:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"There\u2019s a problem with the underlying stream, and we need to restart the server, reset offsets, or recreate a topic"),(0,s.kt)("li",{parentName:"ul"},"We want to ingest data from different streams into the same table."),(0,s.kt)("li",{parentName:"ul"},"We made a mistake in our ingestion config in Pinot, and it\u2019s now throwing exceptions and isn\u2019t able to ingest any more data.")),(0,s.kt)("p",null,"The 0.11 release adds the following REST API endpoints:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"/tables/{tableName}/pauseCompletion"),(0,s.kt)("li",{parentName:"ul"},"/tables/{tableName}/resumeCompletion")),(0,s.kt)("p",null,"As the names suggest, these endpoints can be used to pause and resume streaming ingestion for a specific table. This release also adds the /tables/{tableName}/pauseStatus endpoint, which returns the pause status for a table."),(0,s.kt)("p",null,"Let\u2019s see how to use this functionality with help from a worked example."),(0,s.kt)("h2",{id:"data-generation"},"Data Generation"),(0,s.kt)("p",null,"Let\u2019s imagine that we want to ingest events generated by the following Python script:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'import datetime\nimport uuid\nimport random\nimport json\n\nwhile True:\n    ts = datetime.datetime.now().strftime("%Y-%m-%dT%H:%M:%S.%fZ")\n    id = str(uuid.uuid4())\n    count = random.randint(0, 1000)\n    print(\n        json.dumps({"tsString": ts, "uuid": id, "count": count})\n    )\n')),(0,s.kt)("p",null,"We can view the data generated by this script by pasting the above code into a file called datagen.py and then running the following command:"),(0,s.kt)("p",null,"python datagen.py 2>/dev/null | head -n3 | jq"),(0,s.kt)("p",null,"We\u2019ll see the following output:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "tsString": "2022-11-23T12:08:44.127481Z",\n  "uuid": "e1c58795-a009-4e21-ae76-cdd66e090797",\n  "count": 203\n}\n{\n  "tsString": "2022-11-23T12:08:44.127531Z",\n  "uuid": "4eedce04-d995-4e99-82ab-6f836b35c580",\n  "count": 216\n}\n{\n  "tsString": "2022-11-23T12:08:44.127550Z",\n  "uuid": "6d72411b-55f5-4f9f-84e4-7c8c5c4581ff",\n  "count": 721\n}\n')),(0,s.kt)("p",null,"We\u2019re going to pipe this data into a Kafka stream called \u2018events\u2019 like this:"),(0,s.kt)("p",null,"python datagen.py | kcat -P -b localhost:9092 -t events"),(0,s.kt)("p",null,"We\u2019re not setting a key for these messages in Kafka for simplicity\u2019s sake, but Robin Moffat has an ",(0,s.kt)("a",{parentName:"p",href:"https://rmoff.net/2020/09/30/setting-key-value-when-piping-from-jq-to-kafkacat/"},"excellent blog post that explains how to do it"),"."),(0,s.kt)("h2",{id:"pinot-schematable-config"},"Pinot Schema/Table Config"),(0,s.kt)("p",null,"We want to ingest this data into a Pinot table with the same name. Let\u2019s first define a schema:"),(0,s.kt)("p",null,"Schema:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "schemaName": "events",\n  "dimensionFieldSpecs": [{"name": "uuid", "dataType": "STRING"}],\n  "metricFieldSpecs": [{"name": "count", "dataType": "INT"}],\n  "dateTimeFieldSpecs": [\n    {\n      "name": "ts",\n      "dataType": "TIMESTAMP",\n      "format": "1:MILLISECONDS:EPOCH",\n      "granularity": "1:MILLISECONDS"\n    }\n  ]\n}\n')),(0,s.kt)("p",null,"Note that the timestamp field is called ts and not tsString, as it is in the Kafka stream. We will transform the DateTime string value held in that field into a proper timestamp using a transformation function.\xa0"),(0,s.kt)("p",null,"Our table config is described below:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-json"},'{\n    "tableName":"events",\n    "tableType":"REALTIME",\n    "segmentsConfig":{\n      "timeColumnName":"ts",\n      "schemaName":"events",\n      "replication":"1",\n      "replicasPerPartition":"1"\n    },\n    "tableIndexConfig":{\n      "loadMode":"MMAP",\n      "streamConfigs":{\n        "streamType":"kafka",\n        "stream.kafka.topic.name":"events",\n        "stream.kafka.broker.list":"kafka-pause-resume:9093",\n        "stream.kafka.consumer.type":"lowlevel",\n        "stream.kafka.consumer.prop.auto.offset.reset":"smallest",\n        "stream.kafka.consumer.factory.class.name":"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory",\n        "stream.kafka.decoder.class.name":"org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder",\n      }\n    },\n    "ingestionConfig":{\n      "transformConfigs": [\n        {\n            "columnName": "ts",\n            "transformFunction": "FromDateTime(tsString, \'YYYY-MM-dd\'\'T\'\'HH:mm:ss.SS\'\'Z\'\'\')"\n        }\n      ]\n    },\n    "tenants":{},\n    "metadata":{}\n  }\n')),(0,s.kt)("p",null,"Our transformation has a subtle error. The second parameter passed to the FromDateTime function describes the format of the DateTime string, which we defined as:"),(0,s.kt)("p",null,"YYYY-MM-dd''T''HH:mm:ss.SS''Z''"),(0,s.kt)("p",null,"But tsString has values in the following format:"),(0,s.kt)("p",null,"2022-11-23T12:08:44.127550Z"),(0,s.kt)("p",null,"i.e., we don\u2019t have enough S values - there should be 5 rather than 2.\xa0"),(0,s.kt)("p",null,"If we create the table using the following command:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-bash"},"docker run \\\n   --network  pause-resume \\\n   -v $PWD/pinot/config:/config \\\n   apachepinot/pinot:0.11.0-arm64 AddTable \\\n     -schemaFile /config/schema.json \\\n     -tableConfigFile /config/table.json \\\n     -controllerHost pinot-controller-pause-resume \\\n    -exec \n")),(0,s.kt)("p",null,"Pinot will immediately start trying to ingest data from Kafka, and it will throw a lot of exceptions that look like this:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-log"},"java.lang.RuntimeException: Caught exception while executing function: fromDateTime(tsString,'YYYY-MM-dd'T'HH:mm:ss.SS'Z'')\n\u2026\nCaused by: java.lang.IllegalStateException: Caught exception while invoking method: public static long org.apache.pinot.common.function.scalar.DateTimeFunctions.fromDateTime(java.lang.String,java.lang.String) with arguments: [2022-11-23T11:12:34.682504Z, YYYY-MM-dd'T'HH:mm:ss.SS'Z']\n\n")),(0,s.kt)("p",null,"At this point, we\u2019d usually be stuck and would need to fix the transformation function and then restart the Pinot server. With the pause/resume feature, we can fix this problem without resorting to such drastic measures.\xa0"),(0,s.kt)("h2",{id:"the-pauseresume-flow"},"The Pause/Resume Flow"),(0,s.kt)("p",null,"Instead, we can follow these steps:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"Pause ingestion for the table"),(0,s.kt)("li",{parentName:"ul"},"Fix the transformation function"),(0,s.kt)("li",{parentName:"ul"},"Resume ingestion"),(0,s.kt)("li",{parentName:"ul"},"Profit $$$")),(0,s.kt)("p",null,"We can pause ingestion by running the following command:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-bash"},'curl -X POST \\\n  "http://localhost:9000/tables/events/pauseConsumption" \\\n  -H "accept: application/json"\n')),(0,s.kt)("p",null,"The response should be something like this:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "pauseFlag": true,\n  "consumingSegments": [\n    "events__0__0__20221123T1106Z"\n  ],\n  "description": "Pause flag is set. Consuming segments are being committed. Use /pauseStatus endpoint in a few moments to check if all consuming segments have been committed."\n}\n')),(0,s.kt)("p",null,"Let\u2019s follow the response\u2019s advice and check the consuming segments status:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-bash"},'curl -X GET \\\n  "http://localhost:9000/tables/events/pauseStatus" \\\n  -H "accept: application/json"\n')),(0,s.kt)("p",null,"We\u2019ll see the following response:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "pauseFlag": true,\n  "consumingSegments": []\n}\n')),(0,s.kt)("p",null,"So far, so good. Now we need to fix the table. We have a config, table-fixed.json, that contains a working transformation config. These are the lines of interest:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-json"},'{\n    "ingestionConfig":{\n      "transformConfigs": [\n        {\n            "columnName": "ts",\n            "transformFunction": "FromDateTime(tsString, \'YYYY-MM-dd\'\'T\'\'HH:mm:ss.SSSSSS\'\'Z\'\'\')"\n        }\n      ]\n    }\n}\n')),(0,s.kt)("p",null,"We now have five S values rather than two, which should sort out our ingestion."),(0,s.kt)("p",null,"Update the table config:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-bash"},'curl -X PUT "http://localhost:9000/tables/events" \\\n -H "accept: application/json" \\\n -H "Content-Type: application/json" \\\n -d @pinot/config/table-fixed.json\n')),(0,s.kt)("p",null,"And then resume ingestion. You can pass in the query string parameter consumeFrom, which takes a value of smallest or largest. We\u2019ll pass in smallest since no data has been consumed yet:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-bash"},'curl -X POST \\\n  "http://localhost:9000/tables/events/resumeConsumption?consumeFrom=smallest" \\\n  -H "accept: application/json"\n')),(0,s.kt)("p",null,"The response will be like this:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "pauseFlag": false,\n  "consumingSegments": [],\n  "description": "Pause flag is cleared. Consuming segments are being created. Use /pauseStatus endpoint in a few moments to double check."\n}\n')),(0,s.kt)("p",null,"Again, let\u2019s check the consuming segments status:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-bash"},'curl -X GET \\\n  "http://localhost:9000/tables/events/pauseStatus" \\\n  -H "accept: application/json"\n')),(0,s.kt)("p",null,"This time we will see some consuming segments:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "pauseFlag": false,\n  "consumingSegments": [\n    "events__0__22__20221123T1124Z"\n  ]\n}\n')),(0,s.kt)("p",null,"Navigate to ",(0,s.kt)("a",{parentName:"p",href:"http://localhost:9000/#/query"},"http://localhost:9000/#/query")," and click on the events table. You should see the following:"),(0,s.kt)("p",null,(0,s.kt)("img",{parentName:"p",src:"https://www.datocms-assets.com/75153/1669668611-image2.png",alt:"Sample events table containing records",title:"Sample events table containing records"})),(0,s.kt)("p",null,"We have records! We can also run our data generator again, and more events will be ingested."),(0,s.kt)("h2",{id:"summary"},"Summary"),(0,s.kt)("p",null,"This feature makes real-time data ingestion a bit more forgiving when things go wrong, which has got to be a good thing in my book."),(0,s.kt)("p",null,"When you look at the name of this feature, it can seem a bit esoteric and perhaps not something that you\u2019d want to use, but I think you\u2019ll find it to be extremely useful."),(0,s.kt)("p",null,"So give it a try and let us know how you get on. If you have any questions about this feature, feel free to join us on ",(0,s.kt)("a",{parentName:"p",href:"https://stree.ai/slack"},"Slack"),", where we\u2019ll be happy to help you out."))}h.isMDXComponent=!0}}]);